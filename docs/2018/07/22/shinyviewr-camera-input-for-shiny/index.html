
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">

<head>
<title>Live Free or Dichotomize - Shinyviewr: camera input for shiny</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="">
<meta name="keywords" content="">
<meta name="author" content="Live Free or Dichotomize">
<meta name="generator" content="Hugo 0.45" />

  
<link rel="stylesheet" href="../../../../css/github-gist-lucy.css" rel="stylesheet" id="theme-stylesheet">
<script src="../../../../js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>




<link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/pure-min.css">


    <link rel="stylesheet" href="http://yui.yahooapis.com/pure/0.6.0/grids-responsive-min.css">








<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">


<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>


<link rel="stylesheet" href="../../../../css/tuftesque.css">
<style>
body {
  
    background-color: #fffff8;
  
}
</style>



<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-92165973-1', 'auto');
  ga('send', 'pageview');
</script>


</head>

<body>
<div id="layout" class="pure-g">
<article class="pure-u-1">
<header class="brand">
  <h1>
    <a href="../../../../">
      <span id = "blog_logo">
         <img src="../../../../images/logo.png" alt="Blog Logo" style="height: 40px; width:40px">
      </span>
      
    </a>
  </h1>
</header>

<section>
  <h1 class="content-title">
  
  <a href="../../../../2018/07/22/shinyviewr-camera-input-for-shiny/">Shinyviewr: camera input for shiny</a>
  
  </h1>
  
  
  
  <span class="content-meta">
    
  
  
  
  <i class="fa fa-user">&nbsp;</i><span class="author">
    &nbsp;Nick Strayer</span> <br>
    
  
  
  
  <i class="fa fa-calendar"></i>
    &nbsp;Jul 22, 2018
  
  
  
  &nbsp;<i class="fa fa-clock-o"></i>
    &nbsp;6 min read
  
  
  
  <br>
    <i class="fa fa-tags"> </i>
    
    <a  href="../../../../categories/shiny">shiny</a>
    
    <a  href="../../../../categories/images">images</a>
    
    <a  href="../../../../categories/deeplearning">deeplearning</a>
    
    
    </span>
    
    
    </section>


<section><div id="motivation" class="section level2">
<h2>Motivation</h2>
<p>My package <code>shinysense</code> has been around for more than a year now. It started as a package to add swiping via touch screens to shiny for our app <a href="https://jhubiostatistics.shinyapps.io/papr">Papr</a>, but then slowly got built to include functions for hearing (<code>shinyearr</code>), movement (<code>shinymovr</code>), and drawing (<code>shinydrawr</code>). However one major sense was missing: vision.</p>
<p>I had it on the to-do list for the package for a while but never got around to it. Then last week <a href="https://deanattali.com/">Dean Attali</a> <a href="https://github.com/nstrayer/shinysense/issues/21">pinged me on github</a> about the status of the camera-functionality to <code>shinysense</code>.</p>
<p>This, along with my recent dive into deep learning, spurred a renewed effort to add vision to shiny’s senses. The result is the new function <code>shinyviewr</code>, which, like the rest of <code>shinysense</code>, comes in the form of a shiny module that can be easily added to your app to endow it with the ability to sense the outside world.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">
Coming soon to a shiny app near you: webcam input! <a href="https://twitter.com/hashtag/rstats?src=hash&amp;ref_src=twsrc%5Etfw">#rstats</a> <br>(Spurred on by <a href="https://twitter.com/daattali?ref_src=twsrc%5Etfw"><span class="citation">@daattali</span></a>) <a href="https://t.co/1Qav8ftDJs">pic.twitter.com/1Qav8ftDJs</a>
</p>
— Nick Strayer (<span class="citation">@NicholasStrayer</span>) <a href="https://twitter.com/NicholasStrayer/status/1020358336527708160?ref_src=twsrc%5Etfw">July 20, 2018</a>
</blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
<div id="how-to-use" class="section level2">
<h2>How to use</h2>
<p>In this code I will supply demo code in the form of single page shiny apps. This means the UI and Server code are all contained in a single <code>.R</code> file. This makes reproducing everything easier for you. Just copy and paste the block into an RStudio console and run!</p>
<p><strong>Setup</strong></p>
<p>Before you can run these examples you will need to have the latest version of <code>shinysense</code> downloaded from github. In addition, we will be running an example with a deep learning model obtained via the library Keras. Run these commands before to make sure you’re all setup.</p>
<pre class="r"><code># Installs latest version of shinysense.
devtools::install_github(&#39;nstrayer/shinysense&#39;)

# Installs latest version of keras. 
devtools::install_github(&#39;rstudio/keras&#39;)

# Make sure you have the python versions of keras/tensorflow installed on your machine.
keras::install_keras()</code></pre>
<p>Now that all that is out of the way let’s start with the most basic example.</p>
<pre class="r"><code>library(shiny)
library(shinysense)
library(tidyverse)

ui &lt;- fluidPage(
  shinyviewrUI(&quot;myCamera&quot;, height = &#39;200px&#39;),
  imageOutput(&quot;snapshot&quot;)
)

server &lt;- function(input, output) {
  #server side call of the drawr module
  myCamera &lt;- callModule(
    shinyviewr, &quot;myCamera&quot;, 
    outputHeight = 300,
    outputWidth = 400)

  # logic for what happens after a user has drawn their values. 
  observeEvent(myCamera(), {
    photo &lt;- myCamera() 
    print(photo) #print to console for inspection
    output$snapshot &lt;- renderPlot({
      plot(as.raster(photo)) # plot photo
    })
  })
}

# Run the application
shinyApp(ui = ui, server = server)</code></pre>
<p><strong>Result:</strong></p>
<p><img src="../../../../viewr_post/basic_viewr_app.png" height=400px /></p>
<p>We have a working app!</p>
</div>
<div id="output-format" class="section level2">
<h2>Output format</h2>
<p>A fair question at this point would be “in what form does the image show up in shiny?” If you run the above example and look at the console you will see the image object printed. It is a rather simple thing: just a 3D array with the dimensions <code>(height, width, channels)</code>, with <code>channels</code> being red, green, and blue quantities on a scale from 0-1.</p>
<pre class="r"><code>dim(photo)
&gt; [1] 300 400   3</code></pre>
<p>To plot, you can do what we did in the example, just send it to the <code>as.raster</code> function and then plot the resultant raster object.</p>
</div>
<div id="usage-on-phones" class="section level2">
<h2>Usage on phones</h2>
<p>Having a webcam view is interesting but ultimately rather limiting. One of the more powerful features of shiny is the ability of the apps to run anywhere, including on a phone.</p>
<p><code>shinyviewr</code> can automatically detect that it is running on a phone with a rear camera and will append to its UI a drop down menu to choose between which camera you use to take a photo.</p>
<div style="display: flex; flex-wrap: wrap">
<div>
<p>Front camera:
<img src="../../../../viewr_post/front_camera.png" height=200px width=200px /></p>
</div>
<div>
<p>Rear camera:
<img src="../../../../viewr_post/rear_camera.png" height=200px width=200px /></p>
</div>
</div>
<p>The ability to utilize rear-facing cameras on mobile devices hopefully opens up opportunities for researchers to collect data and run models right in the field, without having to awkwardly plug in an SD card and run a script later. Collect your data and run your model right in the moment!</p>
</div>
<div id="example-app" class="section level2">
<h2>Example app</h2>
<p>Taking a photo and just plotting it is… kind of lame. The real power of image input into shiny is, in my opinion, the easy interfacing with powerful machine learning libraries. To demonstrate this, let’s build an app that attempts to classify whatever is in the photo you just took.</p>
<p>This is where Keras comes in from the setup script. We will use a pre-trained model that has been trained to recognize 1,000 different image classes from a dataset called ‘imagenet.’ Keras includes easy helpers to access multiple different models that have been already trained on this massive dataset for you, vastly simplifying your workload.
We will load the model <code>vgg50</code>. <label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">In order to speed up your app, before you run the example, make sure to run the line loading the model. The first time this line is run it will go and fetch the (rather hefty) file containing the weights. After it’s run the first time it doesn’t need to be downloaded again though.</span></p>
<p><strong>Image classification example</strong></p>
<pre class="r"><code>library(shiny)
library(shinysense)
library(tidyverse)
library(keras)

# instantiate the model
model &lt;- application_resnet50(weights = &#39;imagenet&#39;)

ui &lt;- fluidPage(
  titlePanel(&quot;Image Classifier&quot;),
  fluidRow(
    column(
      width = 7,
      h3(&quot;Webcam&quot;),
      shinyviewrUI(&quot;myCamera&quot;, height = &#39;250px&#39;)
    ),
    column(
      width = 4, offset = 1,
      h3(&#39;Last Photo&#39;),
      imageOutput(&quot;snapshot&quot;, height = &#39;250px&#39;)
    )
  ),
  h3(&quot;Predictions&quot;),
  plotOutput(&quot;predPlot&quot;)
)


server &lt;- function(input, output) {
  #server side call of the drawr module
  myCamera &lt;- callModule(
    shinyviewr, &quot;myCamera&quot;, 
    outputWidth = 500, 
    outputHeight = 500
  )
  
  observeEvent(myCamera(), {
    
    photo &lt;- myCamera() 
    photo_processed &lt;- photo %&gt;% 
      image_array_resize(224, 224) %&gt;% 
      {.*255} %&gt;%  #get image to 0-255 instead of 0-1
      array_reshape(c(1, dim(.))) %&gt;% 
      imagenet_preprocess_input()
    
    # make predictions then decode and print them
    preds &lt;- model %&gt;% 
      predict(photo_processed) %&gt;% 
      imagenet_decode_predictions(top = 20) %&gt;% 
      .[[1]]
    
    output$predPlot &lt;- renderPlot({
        ggplot(preds, 
          aes(x = reorder(class_description, score), y = score)
        ) +
        geom_pointrange(aes(ymin = 0, ymax = score)) +
        coord_flip()
    })
    output$snapshot &lt;- renderPlot({
      plot(as.raster(photo))
    })
  })
}
shinyApp(ui = ui, server = server)</code></pre>
<p>While that may seem like a lot of code to look at. Keep in mind that it is everything needed to spin up an app that uses the deep learning to classify images coming from the camera of your phone or computer. It’s pretty crazy how few lines it is in that context!</p>
<p><label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">The demo app linked will look a tad bit different from what you get if you run the code above. This is because I modified it with some stylistic changes that just added more code to the already long chunk above. If you want to see the exact code generating the demo app check out <a href="https://github.com/nstrayer/viewr_imagenet_demo/blob/master/basic_demo.R">the repo.</a></span>
Here’s a snapshot of the results when running on my phone.</p>
<p><img src="../../../../viewr_post/beer_classify.png" height = 400px /></p>
<p><a href="https://nstrayer.shinyapps.io/viewr_imagenet">Here’s a link</a> to a live demo app for you to check out the app without having to run the code above. Beware, the app is hosted on the free tier of shinyapps.io so there’s a decent chance it will not work by the time you read this. If this is the case, just running the code above will accomplish the same thing!</p>
</div>
</section>
<section>
  

  
    
    
    
    
    
    
    
    

    
    <hr/>
    <div class="author_blurb">
        <div class="author_photo">
          <div class="photo">
            <img style = "border-radius: 25px;" src="https://avatars0.githubusercontent.com/u/6764693?v=3&amp;u=c9c491a636605fe3d6122defb43eb367b3d9381f&amp;s=400" alt="Nick Strayer image" width="90" height="90">
          </div>
        </div>
        <div class = "author_info">
          <div class = "contact_info">
              <span class = "name"> 
                Nick Strayer 
              </span>
              
              <span class = "social_links">
                 
                  <a class = "social_buttons" href = http://nickstrayer.me >
                      <img style="width:20px;" src = "http://image.flaticon.com/icons/png/128/12/12195.png"/>
                  </a>
                
                
                  <a class="social_buttons" href = https://twitter.com/NicholasStrayer>
                    <img style="width:22px;" src = "https://cdn1.iconfinder.com/data/icons/logotypes/32/twitter-128.png"/>
                  </a>
                
                
                  <a class = "social_buttons" href = https://github.com/nstrayer >
                    <img style="width:23px;" src = "https://a248.e.akamai.net/assets.github.com/images/icons/emoji/octocat.png"/>
                  </a>
                
              </span>  
              
          </div>
          <div class = "bio">
            <p class = "bio_text">Randomly walking my way though a career in statistics</p>
          </div>
        </div>
      </div>
    
  
  



  


  <div id="disqus_thread"></div>
    <script type="text/javascript">
       
      var disqus_shortname = 'livefreeordichotomize'; 
      var disqus_identifier = '\/2018\/07\/22\/shinyviewr-camera-input-for-shiny\/';
       
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


      
  <footer class="page-footer">
		<hr>
		<ul class="page-footer-menu">
		
		</ul>

  

	<div class="copyright">
	<p>
    
      &copy;2018
    .
    All rights reserved.
    
    <a href = "http://livefreeordichotomize.com/about/"> About the authors. </a>
  </p>
</div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    });
    </script>
    <script type="text/javascript"
      src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
</footer>

</section>
</article>
</div>
</body>
</html>
