<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Uncertainty on Live Free or Dichotomize</title>
    <link>/tags/uncertainty/</link>
    <description>Recent content in Uncertainty on Live Free or Dichotomize</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Dec 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/tags/uncertainty/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Leveraging uncertainty information from deep neural networks for disease detection - a summary</title>
      <link>/2017/12/24/leveraging-uncertainty-information-from-deep-neural-networks-for-disease-detection---a-summary/</link>
      <pubDate>Sun, 24 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/2017/12/24/leveraging-uncertainty-information-from-deep-neural-networks-for-disease-detection---a-summary/</guid>
      <description>As a biostatistician in the deep learning world I have the awkward task of balancing the dogma of statistics (everything is uncertain) along with the alluring success of some of the newest crazy complex neural network architectures. Going onto any Kaggle competition or new paper âŠ•Such as the popular but arguably flawed paper on diagnosing from radiological screens from Andrew Ng et al. you will see models with millions of parameters performing seemingly magical tasks on data of all kinds.</description>
    </item>
    
  </channel>
</rss>