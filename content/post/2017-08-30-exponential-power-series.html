---
title: "The Exponential Power Series"
author: "Nick Strayer"
date: '2017-08-14'
categories: ["statistics", "visualization", "interactive"]
tags: ["statistics", "visualization", "interactive"]
excerpt: "I find series expansions fascinating. I also find any math envolving e to be fascinating. Here I explain some of the facets of the exponential power series and its connection to my favorite distribution, the Poisson."
---



<p>I am a big fan of the Poisson distribution, there’s something about its simplicity and elegance (I really like <span class="math inline">\(\lambda\)</span>s) that makes it way easier to deal with than some monstrosity like the gamma or normal distribution.</p>
<p>Another thing I am a big fan of is the book I am currently reading: <a href="https://www.amazon.com/Surely-Feynman-Adventures-Curious-Character/dp/0393316041/">Surely You’re Joking, Mr Feynman</a>. In one of the chapters, Dr. Feynman discusses his interest in the power series expansion of <span class="math inline">\(e^x\)</span>, and how efficient it is. Naturally I agreed with him, because this same power series expansion is the formula from which the Poisson distribution is derived. Let’s show this real quick:</p>
<div id="power-series-and-the-poisson" class="section level3">
<h3>Power Series and the Poisson</h3>
<p>First let’s start with the power series:</p>
<p><span class="math display">\[\begin{aligned}
e^{\lambda} = &amp; \sum_{n = 0}^{\infty} \frac{\lambda ^ n}{n!} &amp;&amp; \\
e^{\lambda}/e^{\lambda} = &amp; \sum_{n = 0}^{\infty} \frac{\lambda ^ n}{n!} /e^{\lambda}&amp;&amp;  \text{divide by }e^{\lambda}\\
1 = &amp; \sum_{n = 0}^{\infty} \frac{e^{-\lambda}\lambda ^ n}{n!}&amp;&amp; \text{simplify }\\
\end{aligned}\]</span></p>
<p>We can see that by simply dividing the power series representation by <span class="math inline">\(e^{\lambda}\)</span> (aka multiplying by <span class="math inline">\(e^{-\lambda}\)</span>) we get a series that sums to one, when we have a series (or integral) that comes out to one, that (usually) means we’re dealing with a distribution function. <label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">This idea of making a probability distribution out of basically any series that sums or integrates to one is a trick that will come in massively handy anytime you’re doing any sort of probability theory work. Simply find the constant and divide by it to switch back and forth between a series/ probability.</span> In this case it’s the Poisson. To get the probability mass function (since we are dealing with the nicer discrete case) we simply take a single step of this function, aka <span class="math inline">\(\frac{e^{-\lambda}\lambda ^ n}{n!}\)</span>.</p>
<p>This means that any probability associated with a specific count for a poisson distributed variable is simply a scaled step in the power series expansion of <span class="math inline">\(e^{\lambda}\)</span>! This is the kind of stuff that gets me excited.</p>
</div>
<div id="investigating-the-power-series" class="section level3">
<h3>Investigating the power series</h3>
<p>Let’s go back to the power series and investigate its form:</p>
<p><span class="math display">\[\begin{aligned}
e^{\lambda} = &amp; \sum_{n = 0}^{\infty} \frac{\lambda ^ n}{n!} = 1/1 + \lambda/1 + \lambda^2 / 2 + ...
\end{aligned}\]</span></p>
<p>We see the first term is always 1 <label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">You can use the fact that the first term in this power expansion is one to reason about why something raised to the zero power is one and not zero.</span> and then after that we get a series of terms that change in size following a nice pattern. To get the <span class="math inline">\(i^{th}\)</span> step we simply take the <span class="math inline">\((j - 1)^{th}\)</span> step and multiply it by <span class="math inline">\(\lambda\)</span> and divide it by <span class="math inline">\(j\)</span> (<span class="math inline">\(s_{j+ 1} = s_j\lambda/j.\)</span>) It’s quite beautiful in its simplicity. By carrying this process out an infinite number of times our sum will converge to the true value of <span class="math inline">\(e^{\lambda}\)</span>, and rather rapidly at that. <label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">Recognizing patterns like this one can result in massively sped up algorithms. For instance the naive way to calculate this series would be to perform n factorial calculations, where as if you use the iterative pattern described you only ever have to multiply and divide at each step.</span></p>
<p>In order to demonstrate this I have put together a little interactive that allows you to fiddle with the exponent for <span class="math inline">\(e^{\lambda}\)</span> and the number of times you carry out this sum operation and see how well the series approximates the true value.</p>
<p>The bar plot shows the size of each step, aka how big is <span class="math inline">\(\lambda^i/i!\)</span>, above this is the sum of all of the bars, aka the series estimate of <span class="math inline">\(e^{\lambda}\)</span> at the number of steps you have specified.</p>
<style>
svg text {
  font-family: garamond;
}
</style>
<div id="viz" class="fullwidth">

</div>
<script src="https://cdn.rawgit.com/gka/d3-jetpack/master/build/d3v4%2Bjetpack.js"></script>
<script src="https://d3js.org/d3-scale-chromatic.v1.min.js"></script>
<script src="https://rawgit.com/nstrayer/slid3r/master/dist/slid3r.js"></script>
<script src="/js/bundle.js"></script>
<p><label for="tufte-mn-" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-" class="margin-toggle"><span class="marginnote">Note that as you increase the exponent the number of steps you need to get a good estimate increases with it, why might this be?</span></p>
<p>Do you have a favorite series or mathematical construct? Let me know!</p>
</div>
<div id="adendum" class="section level3">
<h3>Adendum</h3>
<p>I really am a large fan of the Poisson distribution, so much so I even have it permanently written on my body.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">
Finally did it. Guess im stuck with this statistics thing now. <a href="https://twitter.com/hashtag/poissonPmf?src=hash">#poissonPmf</a> <a href="https://t.co/DtTPzOiErd">pic.twitter.com/DtTPzOiErd</a>
</p>
— Nick Strayer (<span class="citation">@NicholasStrayer</span>) <a href="https://twitter.com/NicholasStrayer/status/898908684637659136">August 19, 2017</a>
</blockquote>
<script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
