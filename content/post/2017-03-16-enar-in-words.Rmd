---
author: "Lucy D'Agostino McGowan"
comments: true
date: 2017-03-16T14:56:30-04:00
draft: false
image: ""
menu: ""
share: true
tags:
- ENAR
- tidytext
- conferences
- R code
title: "ENAR in words"
excerpt: "I had an absolutely delightful time at ENAR this year. Lots of talk about the intersection between data science & statistics, diversity, and great advancements in statistical methods. Since there was quite a bit of twitter action, I thought I'd do a quick tutorial in scraping twitter data in R."
---

I had an absolutely delightful time at [ENAR](http://www.enar.org) this year. Lots of talk about the intersection between data science & statistics, diversity, and **exceptional** advancements in statistical methods. 

Check out this word cloud of the most commonly tweeted words!

```{r, echo = FALSE, message = FALSE, warning = FALSE}
library('twitteR')
load("../../data/enar_data.rda")

#load packages
library('dplyr')
library('purrr')
library('stringr')
library('tidytext')
library('wordcloud')

#map this into a dataframe
tweets <- map_df(dat, as.data.frame)

#this will drop links & symbols
drop_pattern <- "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https|ht"
#this pattern is great for twitter, includes #,
unnest_pattern <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"

tidy_tweets <- tweets %>% 
  filter( !grepl("#OTORRINO", text)) %>% # we have one tweeter with our hashtag that wasn't at our conference
  mutate(text = str_replace_all(text, drop_pattern, "")) %>%
  unnest_tokens(word, text, token = "regex", pattern = unnest_pattern) %>%
  filter(!word %in% c(stop_words$word,"44pm", "30am"),
         str_detect(word, "[a-z]"),
         !grepl("@", word )) 

cols <- c(brewer.pal(8,"Dark2"), rep(brewer.pal(8,"Dark2"), each = 5) )

set.seed(916)
tidy_tweets %>%
  count(word) %>%
  with(wordcloud(word, n,min.freq=3, random.order =FALSE,colors=cols))
```

Since there was quite a bit of twitter action, I thought I'd do a quick tutorial in scraping twitter data in `R`.

## Get twitter credentials

Go [here](https://apps.twitter.com) and create an app - this will give you a **Consumer key**, **Consumer secret**, **Access token**, & **Access secret**.

## Scrape tweets

We will use the `twitteR` package to scrape the tweets using the `searchTwitter` function.

```{r, eval = FALSE}
library('twitteR')
setup_twitter_oauth(consumer_key="PASTE_YOUR_CONSUMER_KEY_HERE", 
                    consumer_secret= "PASTE_YOUR_CONSUMER_SECRET_HERE",
                    access_token="PASTE_YOUR_ACCESS_TOKEN_HERE",
                    access_secret="PASTE_YOUR_ACCESS_SECRET_HERE")

dat <- searchTwitter('#ENAR2017', n = 1e4, since = '2017-03-10')
```

## Wrangle tweets

Now we need to corral these tweets into something we can analyze. We are going to use some data-wrangling packages (`dplyr`, `purrr`ðŸ˜º, and `stringr`) as well as Julia & David's `tidytext`.
<p style = "text-align: right; color: #EB6864; font-size: 10pt; LINE-HEIGHT:14px;">
For more details on how to analyze text, <br/>
check out their book [Text Mining with R](http://tidytextmining.com), <br/>
the code below is modified from one of <br/>
their examples.
</p>

We will then use the `wordcloud` package to display our results.

```{r, eval = FALSE}
#load packages
library('dplyr')
library('purrr')
library('stringr')
library('tidytext')
library('wordcloud')
```

We are going to map the tweets into a lovely dataframe, get rid of unwanted symbols and links, split the tweets into individual words, and filter out some stop words.
```{r, eval = FALSE}
#map this into a dataframe
tweets <- map_df(dat, as.data.frame)

#this will drop links & symbols
drop_pattern <- "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https|ht"
#this pattern is great for twitter, includes # and @ symbols
unnest_pattern <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"

tidy_tweets <- tweets %>% 
  filter( !grepl("#OTORRINO", text)) %>% # we have one tweeter with our hashtag that wasn't at our conference
  mutate(text = str_replace_all(text, drop_pattern, "")) %>%
  unnest_tokens(word, 
                text, 
                token = "regex", 
                pattern = unnest_pattern) %>%
  filter(!(word %in% stop_words$word),
         str_detect(word, "[a-z]"),
         !grepl("@", word )) 
```

Now it's plotting time!

```{r, eval = FALSE}
cols <- c(brewer.pal(8,"Dark2"), rep(brewer.pal(8,"Dark2"), each = 5) ) #make some colors for our plot

tidy_tweets %>%
  count(word) %>%
  with(wordcloud(word, 
                 n,
                 min.freq = 5,
                 random.order = FALSE,
                 colors = cols))
```


You did it! Easy as [Ï€](https://potpieshop.files.wordpress.com/2016/03/pi-day.jpg?w=665).

![](https://media.giphy.com/media/fBZXu9v0qjjTq/giphy.gif)

For giggles, let's try another word cloud package [`wordcloud2`](https://github.com/lchiffon/wordcloud2). This one is interactive (but not on CRAN, you can install using `devtools::install_github("lchiffon/wordcloud2")`).
 
For a word cloud similar to the one above, we can use the `wordcloud2` function. 
```{r, mval = FALSE}
library('wordcloud2')

tidy_tweets %>%
  count(word) %>%
  filter(n > 2) %>%
  wordcloud2(size = 3, minRotation = -pi/2, maxRotation = -pi/2)

```


```{r, echo = FALSE}
library('wordcloud2')
```


Instead I am going to make an `R` shaped cloud using `letterCloud`!


```{r, message = FALSE, warning = FALSE, fig.align='center'}

tidy_tweets %>%
  count(word) %>%
  filter(n > 1) %>%
  letterCloud(size = 3, word = "R") 
```

