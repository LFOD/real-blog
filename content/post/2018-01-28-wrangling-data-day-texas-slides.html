---
title: Wrangling Data Day Texas Slides
author: "Lucy D'Agostino McGowan"
date: '2018-01-28'
slug: wrangling-data-day-texas-slides
categories: [rstats]
tags: [rstats]
excerpt: "Since twitter threads are excessively cumbersome to navigate, Ma√´lle asked me to relocate the list of #rstats Data Day Texas slides to a blog post, so here we are!"
---



<p>Since <a href="https://twitter.com/LucyStats/status/957628106889711616">twitter threads</a> are <a href="http://livefreeordichotomize.com/2017/07/24/twitter-trees/">excessively cumbersome to navigate</a>, <a href="https://twitter.com/ma_salmon">Ma√´lle</a> asked me to relocate the list of #rstats Data Day Texas slides to a blog post, so here we are!</p>
<p><em>The titles link to the slides</em> üëØ</p>
<div id="pilgrims-progress-a-journey-from-confusion-to-contribution" class="section level2">
<h2><a href="https://github.com/batpigandme/ddtx">Pilgrim‚Äôs Progress: a journey from confusion to contribution</a></h2>
<div id="mara-averick" class="section level3">
<h3><a href="https://twitter.com/dataandme">Mara Averick</a></h3>
<p>Navigating the data science landscape can be overwhelming. Luckily, you don‚Äôt have to do it alone! In fact, I‚Äôll argue shouldn‚Äôt do it alone. Whether it be by tweeting your latest mistake, asking a well-formed question, or submitting a pull request to a popular package, you can help others and yourselves by ‚Äúlearning out loud.‚Äù No matter how much (or little) you know, you can turn your confusion into contributions, and have a surprising amount of fun along the way.</p>
</div>
</div>
<div id="making-causal-claims-as-a-data-scientist-tips-and-tricks-using-r" class="section level2">
<h2><a href="http://www.lucymcgowan.com/talks/2018-01-27_data-day-texas.html">Making Causal Claims as a Data Scientist: Tips and Tricks Using R</a></h2>
<div id="lucy-dagostino-mcgowan" class="section level3">
<h3><a href="https://twitter.com/LucyStats">Lucy D‚ÄôAgostino McGowan</a></h3>
<p>Making believable causal claims can be difficult, especially with the much repeated adage ‚Äúcorrelation is not causation‚Äù. This talk will walk through some tools often used to practice safe causation, such as propensity scores and sensitivity analyses. In addition, we will cover principles that suggest causation such as the understanding of counterfactuals, and applying Hill‚Äôs criteria in a data science setting. We will walk through specific examples, as well as provide R code for all methods discussed.</p>
</div>
</div>
<div id="statistics-for-data-science-what-you-should-know-and-why" class="section level2">
<h2><a href="https://speakerdeck.com/kroz/statistics-for-data-science-what-you-should-know-and-why">Statistics for Data Science: what you should know and why</a></h2>
<div id="gabriela-de-queiroz" class="section level3">
<h3><a href="https://twitter.com/gdequeiroz">Gabriela de Queiroz</a></h3>
<p>Data science is not only about machine learning. To be a successful data person, you also need a significant understanding of statistics. Gabriela de Queiroz walks you through the top five statistical concepts every Data Scientist should know to work with data.</p>
</div>
</div>
<div id="r-what-is-it-good-for-absolutely-everything" class="section level2">
<h2><a href="https://github.com/jasdumas/talks/tree/master/r-data-day-texas#slides">R, What is it good for? Absolutely Everything</a></h2>
<div id="jasmine-dumas" class="section level3">
<h3><a href="https://twitter.com/jasdumas">Jasmine Dumas</a></h3>
<p>Good does not mean great, but good is better than bad. When we try to compare programming languages we tend to look at the surface components (popular developer influence, singular use cases or language development &amp; design choices) and sometimes we forget the substantive (sometimes secondary) components of what can make a programming language appropriate for use, such as: versatility, environment and inclusivity. I‚Äôll highlight each of these themes in the presentation to show and not tell of why R is good for everything!</p>
</div>
</div>
<div id="infer-an-r-package-for-tidy-statistical-inference" class="section level2">
<h2><a href="https://ismayc.github.io/talks/data-day-texas-infer/slide_deck.html">infer: an R package for tidy statistical inference</a></h2>
<div id="chester-ismay" class="section level3">
<h3><a href="https://twitter.com/old_man_chester">Chester Ismay</a></h3>
<p>How do you code-up a permutation test in R? What about an ANOVA or a chi-square test? Have you ever been uncertain as to exactly which type of test you should run given the data and questions asked? The <code>infer</code> package was created to unite common statistical inference tasks into an expressive and intuitive framework to alleviate some of these struggles and make inference more intuitive. This talk will focus on the design principles of the package, which are firmly motivated by Hadley Wickham‚Äôs tidy tools manifesto. It will also discuss the implementation, centered on the common conceptual threads that link a surprising range of hypothesis tests and confidence intervals. Lastly, we‚Äôll walk through some examples of how to implement the code of the <code>infer</code> package. The package is aimed to be useful to new students of statistics as well as seasoned practitioners.</p>
</div>
</div>
<div id="something-old-something-new-something-borrowed-something-blue-ways-to-teach-data-science-and-learn-it-too" class="section level2">
<h2><a href="http://rudeboybert.rbind.io/talk/2018-01-27-data_day_texas/">Something old, something new, something borrowed, something blue: Ways to teach data science (and learn it too!)</a></h2>
<div id="albert-y.-kim" class="section level3">
<h3><a href="https://twitter.com/rudeboybert">Albert Y. Kim</a></h3>
<p>How can we help newcomers take their first steps into the world of data science and statistics? In this talk, I present ModernDive: An Introduction to Statistical and Data Sciences via R, an open source, fully reproducible electronic textbook available at ModernDive.com, co-authored by myself and Chester Ismay, Data Science Curriculum Lead at DataCamp. ModernDive‚Äôs authoring follows a paradigm of ‚Äúversions, not editions‚Äù much more in line with software development than traditional textbook publishing, as it is built using RStudio‚Äôs bookdown interface to R Markdown. In this talk, I will present details on our book‚Äôs construction, our approaches to teaching novices to use tidyverse tools for data science (in particular ggplot2 for data visualization and dplyr for data wrangling), how we leverage these data science tools to teach data modeling via regression, and preview the new infer package for statistical inference, which performs statistical inference using an expressive syntax that follows tidy design principles. We‚Äôll conclude by presenting example vignettes and R Markdown analyses created by undergraduate students to demonstrate the great potential yielded by effectively empowering new data scientists with the right tools.</p>
</div>
</div>
<div id="building-shiny-apps-challenges-and-responsibilities" class="section level2">
<h2><a href="https://austinshiny2018.netlify.com/minnier_shiny_slides.html">Building Shiny Apps: Challenges and Responsibilities</a></h2>
<div id="jessica-minnier" class="section level3">
<h3><a href="https://twitter.com/datapointier">Jessica Minnier</a></h3>
<p>R Shiny has revolutionized the way statisticians and data scientists distribute analytic results and research methods. We can easily build interactive web tools that empower non-statisticians to interrogate and visualize their data or perform their own analyses with methods we develop. However, ensuring the user has an enjoyable experience while guaranteeing the analyses options are statistically sound is a difficult balance to achieve. Through a case study of building START (Shiny Transcriptome Analysis Resource Tool), a shiny app for ‚Äúomics‚Äù data visualization and analysis, I will present the challenges you may face when building and deploying an app of your own. By allowing the non-statistician user to explore and analyze data, we can make our job easier and improve collaborative relationships, but the success of this goal requires software development skills. We may need to consider such issues as data security, open source collaborative code development, error handling and testing, user education, maintenance due to advancing methods and packages, and responsibility for downstream analyses and decisions based on the app‚Äôs results. With Shiny we do not want to fully eliminate the statistician or analyst ‚Äúmiddle man‚Äù but instead need to stay relevant and in control of all types of statistical products we create.</p>
</div>
</div>
<div id="using-r-on-small-teams-in-industry" class="section level2">
<h2><a href="https://t.co/jlmtToUP12">Using R on small teams in industry</a></h2>
<div id="jonathan-nolis" class="section level3">
<h3><a href="https://twitter.com/skyetetra">Jonathan Nolis</a></h3>
<p>Doing statistical analyses and machine learning in R requires many different components: data, code, models, outputs, and presentations. While one person can usually keep track of their own work, as you grow into a team of people it becomes more important to keep coordinated. This session discusses the work we do data science work at Lenati, a marketing and strategy consulting firm, and why R is a great tool for us. It covers the best practices we found for working on R code together over many projects and people, and how we handle the occasional instances where we must use other languages.</p>
</div>
</div>
<div id="the-lesser-known-stars-of-the-tidyverse" class="section level2">
<h2><a href="https://github.com/robinsones/Data-Day-Talk">The Lesser Known Stars of the Tidyverse</a></h2>
<div id="emily-robinson" class="section level3">
<h3><a href="https://twitter.com/robinson_es">Emily Robinson</a></h3>
<p>While most R programmers have heard of ggplot2 and dplyr, many are unfamiliar with the breath of the tidyverse and the variety of problems it can solve. In this talk, we will give a brief introduction to the concept of the tidyverse and then describe three packages you can immediately start using to make your workflow easier. The first package is forcats, designed for making working with categorical variables easier; the second is glue, for programmatically combining data and strings; and the third package is tibble, an alternative to data.frames. We will cover their basic functions so that, at the end of the talk, we will be able to use and learn more about the broader tidyverse.</p>
</div>
</div>
<div id="text-mining-using-tidy-data-principles" class="section level2">
<h2><a href="https://speakerdeck.com/juliasilge/text-mining-with-tidy-data-principles-and-count-based-methods">Text Mining Using Tidy Data Principles</a></h2>
<div id="julia-silge" class="section level3">
<h3><a href="https://twitter.com/juliasilge">Julia Silge</a></h3>
<p>Text data is increasingly important in many domains, and tidy data principles and tidy tools can make text mining easier and more effective. I will demonstrate how we can manipulate, summarize, and visualize the characteristics of text using these methods and R packages from the tidy tool ecosystem. These tools are highly effective for many analytical questions and allow analysts to integrate natural language processing into effective workflows already in wide use. We will explore how to implement approaches such as sentiment analysis of texts, measuring tf-idf, and measuring word vectors.</p>
</div>
</div>
<div id="speeding-up-r-with-parallel-programming-in-the-cloud" class="section level2">
<h2><a href="https://www.slideshare.net/RevolutionAnalytics/speed-up-r-with-parallel-programming-in-the-cloud">Speeding up R with Parallel Programming in the Cloud</a></h2>
<div id="david-smith" class="section level3">
<h3><a href="https://twitter.com/revodavid">David Smith</a></h3>
<p>There are many common workloads in R that are ‚Äúembarrassingly parallel‚Äù: group-by analyses, simulations, and cross-validation of models are just a few examples. In this talk I‚Äôll describe several techniques available in R to speed up workloads like these, by running multiple iterations simultaneously, in parallel. Many of these techniques require the use of a cluster of machines running R, and I‚Äôll provide examples of using cloud-based services to provision clusters for parallel computations. In particular, I will describe how you can use the SparklyR package to distribute data manipulations using the dplyr syntax, on a cluster of servers provisioned in the Azure cloud.</p>
</div>
</div>
<div id="making-magic-with-keras-and-shiny" class="section level2">
<h2><a href="http://nickstrayer.me/dataDayTexas/">Making Magic with Keras and Shiny</a></h2>
<div id="nicholas-strayer" class="section level3">
<h3><a href="https://twitter.com/NicholasStrayer">Nicholas Strayer</a></h3>
<p>The web-application framework Shiny has opened up enormous opportunities for data scientists by giving them a way to bring their models and visualizations to the public in interactive applications with only R code. Likewise, the package keras has simplified the process of getting up and running with deep-neural networks by abstracting away much of the boiler-plate and book-keeping associated with writing models in a lower-level library such as tensorflow. In this presentation, I will demo and discuss the development of a shiny app that allows users to cast ‚Äòspells‚Äô simply by waving their phone around like a wand. The app gathers the motion of the device using the library shinysense and feeds it into a convolutional neural network which predicts spell casts with high accuracy. A supplementary shiny app for gathering data will be also be shown. These applications demonstrate the ability for shiny to be used at both the data-gathering and model-presentation steps of data science.</p>
</div>
</div>
